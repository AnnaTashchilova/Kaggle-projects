# Toxic Comment Classification Challenge
В данном исследовании был выполнен анализ комментариев из Википедии с целью выявления из них токсичных, то есть содержаших насилие, непристойные выражения, ненависть, угрозу и т.д.
Данные для исследования представлены на платформе Kaggle: 
https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge 
и содержат TRAIN выборку, TEST выборку и TEST LABELS, правильная классификация для теста, выложенная после окончания соревнования.
В соревновании предлагается выполнить multilabel классификацию комментариев, то есть один комментарий может принадлежать сразу нескольким классам токсичности:

*   Toxic – обычные токсичные
*   Severe_toxic – сильно токсичные
*   Obscene - непристойные
*   Threat - комментарии, содержащие насилие
*   Insult - комментарии, содержащие угрозу
*   Identity_hate - комментарии, содержащие ненависть к личности

## Preprocessing
Preprocessing играет важную роль в дальнейшей успешной или неуспешной классификации текста. Поэтому для каждого комментария из обучающей и тестовой выборок были проведены следующие операции:

1.   Игнорируются все знаки препинания, цифры, слова, состоящии из одной или двух букв.
2.   Апостроф несет смысловую нагрузку только если находится в середине слова, тогда часть после апострофа убирается, так как не несет смысловой нагрузки.
3.   Далее используется лемматизатор, в который передается часть речи и слово приводится к начальной форме.
4.   На последнем этапе удаляются stop слова из словаря 'english'.

В результате получается список из слов, с которым будет удобно работать.
Пример препроцессинга комментария:
You, sir, are my hero. Any chance you remember what page that's on? ---> ['sir', 'hero', 'chance', 'remember', 'page']

## Bag Of Words
В первом разделе работы воспользуемся простым методом Bag of Words, то есть без какой-либо обработки контекта и т.д., переведем список слов из комментариев в вектор и воспользуемся двумя классификаторами: XGBClassifier, LogicticRegression, и просмотрим на полученные результаты с целью определить приоритетный классификатор, а также выбрать наиболее показательные метрики оценки качества созданной модели.

Выводы XGBClassifier.
1. Малонеселенный класс 'threat' плохо различим подобной моделью.
2. Малочисленный, а главное зависимый от 'toxic', класс 'severe_toxic' также плохо классифицирован.
3. Благодаря хорошей идентификации чистых комментариев, метрика ROC-AUC получилась хорошей - 0.95. 
4. Действительно показательной является метрика F1 - score по классам. Также можно ориентироваться на precision и recall. Рассмотрим classification report, из которого видно, что хуже всего идентифицировались малочисленные классы. А лучше всего (F1-score = 0.57) класс 'obscene' (комментарии, содержащие непристойные выражения), что в целом логично следует из используемого метода 'мешок слов' и названия категории. В ней достаточно найти нужные слова и категория станет легко определяемой.

Выводы LogisticRegression. 
Рассмотрим classification report, из которого видно, что хуже всего по-прежнему идентифицировались малочисленные классы. А лучше всего (F1-score = 0.64) класс 'obscene' и 'toxic'(самый многочисленный). В целом метрика F1-score по всем классам улучшилась и достигла значения 0.59, что лучше, чем аналогичная, полученная в XGBClassifier. Это объяснимо тем, что наилучшие параметры в XGBC не подбирались.

## TF-IDF
Следующим этапом работы был выбран другой способ векторизации текста комментариев с учетом важности контекста (TF-IDF). 
*TF-IDF (TF — term frequency, IDF — inverse document frequency) — статистическая мера, используемая для оценки важности слова в контексте документа, являющегося частью коллекции документов или корпуса. Вес некоторого слова пропорционален частоте употребления этого слова в документе и обратно пропорционален частоте употребления слова во всех документах коллекции.*
Полученный вектор используется для таких же как и на предыдущем этапе двух классификаторов: XGBClassifier, LogicticRegression.

Выводы XGBClassifier.
Рассмотрим classification report, из которого видно, что хуже всего по-прежнему идентифицировались малочисленные классы.  В целом метрика F1-score по всем классам улучшилась и достигла значения 0.53, что лучше, чем аналогичная, полученная в XGBClassifier на первом этапе с помощью BagOfWords. 

Выводы LogisticRegression.
Рассмотрим classification report, из которого видно, что хуже всего по-прежнему идентифицировались малочисленные классы. А лучше всего (F1-score = 0.68) класс 'obscene' и 'toxic'(самый многочисленный). В целом метрика F1-score по всем классам улучшилась и достигла значения 0.64, что лучше, чем аналогичная, полученная тем же методом на предыдущим этапом с помощью BagOfWords, что говорит о важности контекста при анализе тональности текста. Логистическая регрессия лучше справляется, возможно, из-за отсутствия подбора параметров у XGBClassifier.

## DistilBERT
Следующим этапом работы было пострение модели с использованием DistilBERT. Для ее реализации приведем данные в TRAIN и TEST выборках к необходимому формату - 'text' (строка комментария после preprocessing) и 'labels' ( в формате [0, 0, 0, 0, 0]).
DistilBERT обрабатывает предложения и передает извлеченную им информацию в следующую модель. DistilBERT представляет собой уменьшенную версию BERT. Она быстрее и легче, но при этом вполне сравнима в результативности.
Эмбеддинг предложения, полученный с помощью предобученной модели представляет собой вектор размерности 768. Классификация реализуется путем добавления линейного слоя и выходного слоя классификатора.

Выводы
1.   В результате исследования были рассмотрены три способа векторизации текста: Countvectorizer, TF-IDF и предобученная модель BERT. При этом лучше всего с мульти-лабел классификацией справилась последняя модель.
2.   Сравнимо по F1-score справилась с мульти-лабел классификацией модель на основе TF-IDF + логистическая регрессия, она показала чуть ниже значения F1-score по каждому классу, однако основное ее преимущество заключается в отсутсвии необходимости использовать большие вычислительные ресурсы.
3.   Задача мульти-лабел классификации тональности текстов является по-прежнему актуальной. Результаты 'выше среднего', полученные в одной из наиболее эффективных моделей (BERT), это подтверждают.
4.   В данной работе задача мульти-лабел классификации не была полностью решена ввиду сильного дисбаланса как внутри классов токсичности, так и между чистыми (нетоксичными) и токсичными клмментариями.
